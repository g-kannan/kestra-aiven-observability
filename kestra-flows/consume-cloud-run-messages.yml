id: consume-cloud-run-messages
namespace: aiven

tasks:
  - id: consume
    type: io.kestra.plugin.scripts.python.Script
    taskRunner:
      type: io.kestra.plugin.scripts.runner.docker.Docker
      image: python:3.11-slim
    beforeCommands:
      - pip install kafka-python
    inputFiles:
      ca.pem: "{{ read('certs/ca.pem') }}"
      service.cert: "{{ read('certs/service.cert') }}"
      service.key: "{{ read('certs/service.key') }}"
    outputFiles:
      - messages.json
    script: |
      import json
      from kafka import KafkaConsumer

      # Consume messages using kafka-python with SSL (uses PEM files directly!)
      consumer = KafkaConsumer(
          'gcp-cloud-run-fn-events',
          bootstrap_servers='kafka-15145f3d-project-4683.g.aivencloud.com:11353',
          security_protocol='SSL',
          ssl_cafile='ca.pem',
          ssl_certfile='service.cert',
          ssl_keyfile='service.key',
          auto_offset_reset='earliest',
          enable_auto_commit=True,
          group_id='kestra-cg1',
          consumer_timeout_ms=20000,  # 20 seconds timeout
          value_deserializer=lambda x: json.loads(x.decode('utf-8')) if x else None
      )

      messages = []
      count = 0
      max_records = 500

      for message in consumer:
          messages.append({
              'topic': message.topic,
              'partition': message.partition,
              'offset': message.offset,
              'key': message.key.decode('utf-8') if message.key else None,
              'value': message.value,
              'timestamp': message.timestamp
          })
          count += 1
          if count >= max_records:
              break

      consumer.close()

      # Write messages to output file
      with open('messages.json', 'w') as f:
          for msg in messages:
              f.write(json.dumps(msg) + '\n')

      print(f"Consumed {len(messages)} messages")